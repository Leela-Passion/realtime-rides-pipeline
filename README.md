<!-- PROJECT BANNER -->
<p align="center">
  <img src="https://raw.githubusercontent.com/Leela-Passion/realtime-rides-pipeline/main/assets/project_banner.png" width="100%" alt="Project Banner" />
</p>

<h1 align="center">ğŸš• Real-Time Ride Sharing Analytics Platform</h1>
<p align="center">
  <b>Databricks â€¢ Delta Lake â€¢ dbt â€¢ Medallion Architecture â€¢ SCD Type-2 â€¢ SQL</b>
</p>

---

## ğŸ“Œ Project Overview
This project builds a **real-time analytics platform for a ride-sharing company**, showcasing the complete **Medallion Architecture (Bronze â†’ Silver â†’ Gold)** on Databricks with **dbt transformations** and **SCD Type-2 snapshots**.

The project demonstrates **end-to-end data engineering skills**:

- Ingestion â†’ Cleaning â†’ Modelling â†’ SCD â†’ Documentation â†’ Quality Tests â†’ Lineage  
- Ready for **Data Engineer**, **Analytics Engineer**, and **Data Analyst** job roles.

---

## ğŸ—ï¸ Architecture Diagram
Below is the architecture used in this project.

> **Architecture Diagram**
<p align="center">
  <img src="https://raw.githubusercontent.com/yourusername/yourrepo/main/architecture/architecture_design.png" width="90%" alt="Architecture Diagram" />
</p>

---

## ğŸ¯ Problem Solved
Ride-sharing platforms generate large volumes of transactional dataâ€”trips, payments, drivers, vehicles, locations, and customer interactions.

This project solves:
- ğŸš€ **Low-latency reporting** using structured streaming ingestion  
- ğŸ“Š **Reliable analytics** using dbt transformations  
- â™»ï¸ **Historical tracking** using SCD Type-2  
- ğŸ§ª **Data quality assurance** using dbt tests  
- ğŸ” **Lineage & documentation** for transparency  

---

## ğŸ¯ **Project Objectives**

This project showcases a scalable data pipeline designed for:

- **Ingestion â†’ Transformation â†’ Modeling â†’ Documentation**
- **SCD Type-2 Snapshots** using dbt
- **Data quality testing** (unique, not_null, relationships)
- **Dimensional modeling** (Gold layer)
- **High-performance transformations** using Spark SQL
- **Interactive documentation** auto-generated by dbt
- **Dashboard-ready data marts** for analytics

It is intentionally designed for **recruiter readability** + **technical depth**.

---

## âš¡ Features

### ğŸŸ¤ **Bronze Layer â€“ Raw Ingestion**
- Raw CSV/JSON-like data stored in Delta tables
- Notebook: `bronze_ingestion.html`

### ğŸŸ¡ **Silver Layer â€“ Cleaning & Conformance**
- Standardized schemas
- Deduplication using window functions  
- Dynamic transformations notebook  
  (`dynamic_transformations-bronze_to_silver.html`)
- Example entity notebook  
  (`silver_transformation-customers_entity.html`)

### ğŸŸ¢ **Gold Layer â€“ Dimensions & Facts**
- dbt models for Customers, Drivers, Vehicles, Trips, Payments  
- Relationship & quality tests applied in `schema.yml`

### ğŸ“˜ **dbt SCD Type-2 Snapshots**
- Snapshot configs stored under `snapshots/SCDs.yml`  
- CDC using `last_updated_timestamp`  
- Temporal validity using `dbt_valid_to_current`

### ğŸ“š **Interactive Documentation**
- Auto-generated via dbt docs  
- Includes lineage graph, model descriptions, tests, and sources

---

## ğŸ§± Technology Stack

| Layer | Tools |
|------|-------|
| Compute | Databricks SQL / Spark |
| Transformation | **dbt** (core / cloud) |
| Storage | Delta Lake |
| Modeling | SCD Type-2, Star Schema |
| Orchestration | dbt Cloud (online, no local setup) |
| Documentation | dbt docs, GitHub Pages |
| Version Control | GitHub |

---

## ğŸš€ How to Run the Project (NO INSTALLATION REQUIRED)

### **Option 1 â€” Run Online Using dbt Cloud (Recommended)**  
âœ¨ Zero installation  
âœ¨ Browser-based execution  
âœ¨ Saves job logs automatically

**Steps:**
1. Create free account â†’ https://cloud.getdbt.com  
2. Connect to Databricks workspace  
3. Import this GitHub repo  
4. Click **Run** â†’ â€œStart Runâ€  
5. Open **Documentation** & **Lineage Graph** inside dbt Cloud

---

### **Option 2 â€” Open Docs on GitHub Pages**  
If enabled, visit:

ğŸ‘‰ `https://Leela-Passion.github.io/realtime-rides-pipeline/`  
Contains:
- Model documentation  
- Column-level metadata  
- Snapshots  
- DAG lineage graph  

---

## ğŸ“‚ Folder Structure (Clean & Recruiter-Friendly)

```
realtime-rides-pipeline/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ architecture_design.png
|   â”œâ”€â”€ project_banner.png
|
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ bronze_ingestion.html
â”‚   â”œâ”€â”€ silver_transformation-customers_entity.html
â”‚   â”œâ”€â”€ dynamic_transformations-bronze_to_silver.html
â”‚
â”œâ”€â”€ dbt_project/
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ source/
|   |       â”œâ”€â”€ sources.yml
|   |       â”œâ”€â”€ schema.yml
â”‚   â”‚   â”œâ”€â”€ silver/
|           â””â”€â”€ trips.sql
â”‚   â”‚
â”‚   â”œâ”€â”€ snapshots/
â”‚   â”‚    â”œâ”€â”€ fact.yml
|   |    â”œâ”€â”€ SCDs.yml    
â”‚   â”œâ”€â”€ macros/
|   |   â””â”€â”€ generate_schema_name.sql
â”‚   
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ overview.md
    â”œâ”€â”€ data_dictionary.md
    â”œâ”€â”€ dashboard_screenshots/
```

---

## ğŸ§ª dbt Commands Used in CI (no local install needed)

```bash
dbt run
dbt test
dbt snapshot
dbt docs generate
```
## ğŸ§ª Data Quality Tests

Data quality is ensured using **dbt's native testing framework**:

- âœ… `unique` â€” ensures primary keys are not duplicated  
- âœ… `not_null` â€” prevents missing key fields  
- âœ… `relationships` â€” enforces FK constraints across models  
- âœ… Source freshness checks â€” validates timely ingestion  
- âœ… Snapshot date validity â€” ensures SCD2 timelines stay consistent  

---

## ğŸ“Š Data Model Summary

This project follows a **Dimensional Modeling** approach using dbt, designed for scalable analytics and trusted data delivery.

### ğŸ§© Dimensions

- **DimCustomers** â€” customer master data, demographics, sign-up details  
- **DimDrivers** â€” driver profiles, ratings, onboarding details  
- **DimVehicles** â€” vehicle types, registration, attributes  
- **DimLocations** â€” pickup/dropoff standardized location dimension  
- **DimPayments** â€” payment methods, transaction mapping  
- **DimTrips** â€” enriched trip-level metadata for analysis  

### ğŸ“¦ Facts

- **FactTrips** â€” core analytical fact table built from the Gold layer  
  - Includes fares, discounts, surge, duration, distance  
  - Linked via surrogate keys to all dimensional tables  

---

## Output:

-ğŸ“‚ **Model lineage graph**
-ğŸ§¬ **Column-level documentation**
-ğŸ” **Source metadata**
-ğŸ•’ **Snapshot/SCD history**
-ğŸ§ª **Test results dashboard**

## ğŸ“ What This Project Demonstrates (For Recruiters)
### ğŸ¯ Data Engineer
-Medallion architecture
-Distributed ETL using Spark
-Delta Lake ACID + time-travel
-Incremental pipelines
-SCD Type-2 modeling with dbt snapshots

### ğŸ¯ Analytics Engineer

-dbt modeling (staging â†’ core â†’ marts)
-Tests, documentation & macros
-Dimensional modeling
-Data contracts & governed layers
-Reusable SQL transformations

### ğŸ¯ Data Analyst
-Clean, analytics-ready tables
-Trips, Revenue, Driver & Customer metrics
-Ready for dashboards (Power BI / Tableau)
-Example SQL queries included

## ğŸš€ Future Enhancements

-**Add Airflow / Prefect orchestration
-Add Structured Streaming for real-time ingestion
-Add Power BI / Tableau real-time dashboards
-Add DuckDB + MotherDuck for local analytics
-Add CI/CD for dbt + docs deployment
-Publish documentation to GitHub Pages**

## ğŸ’¬ Contact

If you like this project or want to collaborate, feel free to reach out! 
